\chapter{\large Evaluación de la propuesta}\label{Capítulo 3}

\pagestyle{fancy}
\lhead{}
\chead{}
\rhead{Capítulo 3: Evaluación de la propuesta}
\lfoot{}
\cfoot{}
\rfoot{\thepage}
\renewcommand{\headrulewidth}{0.4pt}
%\renewcommand{\footrulewidth}{0.4pt}
\vspace{-1cm}

\section{Introducción}
En este capítulo de presenta la evaluación del método para la integración de datos basado en ontologías OntoIntegra. Para la evaluación se utilizó un caso de estudio sobre dos versiones de la aplicación informática AUCTORITAS. La versión 1.0 fue desarrollada sin tomar en cuenta el método propuesto, mientras que la versión 2.0 fue desarrollada con un acceso a datos concebido acorde al método OntoIntegra.

\section{Selección de la estrategia de evaluación}
Dependiendo del propósito de la evaluación y de las condiciones de la investigación empírica, existen tres grandes tipos de estrategias que pueden utilizarse: encuestas, casos de estudio y experimentos \citep{Wohlin2012}.

Una encuesta es un sistema para recolectar información sobre o acerca de personas que describen, comparan o explican su conocimiento, actitudes y comportamiento \citep{Wohlin2012}. Una encuesta no permite el control sobre la ejecución de la medición, por lo que no es posible manipular variables como en otros métodos de investigación \citep{Wohlin2012}.

Los casos de estudio en la ingeniería de software son investigaciones empíricas que se basan en múltiples fuentes de evidencia para investigar una instancia (o un pequeño número de ellas) de un fenómeno de ingeniería de software contemporáneo dentro de su contexto real, especialmente cuando el límite entre el fenómeno y el contexto no puede ser claramente definido \citep{Runeson:2012:CSR:2361717,Wohlin2012}. Constituyen una técnica donde factores clave que pueden incidir en la salida se identifican y se documenta la actividad \citep{stake1995art}. 

Los experimentos (o experimentos controlados) en la ingeniería de software son un tipo de investigación empírica que manipula un factor o variable de la configuración estudiada. Basado en la aleatoriedad se aplican diferentes tratamientos a diferentes sujetos, mientras se mantienen otras variables constantes y se miden los efectos en las variables de salida \citep{Wohlin2012}. Constituyen una investigación formal, rigorosa y controlada en la que los factores claves son identificados y manipulados, mientras que otros factores en el contexto se mantienen sin cambio. 

La diferencia entre casos de estudio y experimentos está determinada por el nivel de control del contexto \citep{Petersen:2009:CIS:1671248.1671293}. En un experimento diferentes situaciones son forzadas deliberadamente y el objetivo comúnmente es distinguir entre las dos situaciones. En un caso de estudio el contexto es controlado por el proyecto real analizado \citep{Wohlin2012}. Basados en los elementos expuestos, el autor de la presente investigación concluye que la realización de un caso de estudio constituye una estrategia viable para la evaluación de la misma. 

\section{Preparación del caso de estudio}
Según \cite{kitchenham1995case} para evitar el sesgo y asegurar la validez interna, es necesario crear una base sólida para evaluar los resultados de un caso de estudio. \cite{kitchenham1995case} proponen tres alternativas para preparar un estudio con el fin de facilitar esto:

\begin{itemize}
\item Una comparación de los resultados aplicando el método contra una línea base es una solución.
\item Un proyecto hermano puede ser seleccionado como línea base. El proyecto bajo estudio emplea el nuevo método mientras que el proyecto hermano usa los métodos anteriores. Ambos proyectos deben ser comparables.
\item Si el método se aplica a componentes del producto individuales, debe ser aplicado aleatoriamente a algunos componentes y a otros no.
\end{itemize}

Para el caso de estudio en cuestión se utilizarán las versiones 1.0 y 2.0 de la aplicación informática AUCTORITAS. La versión 1.0 de AUCTORITAS utiliza un acceso a datos incrustado en el código fuente de la aplicación y, para incorporar nuevas fuentes de datos, es necesario modificar su código fuente.

El acceso a datos de la versión 2.0 de AUCTORITAS se desarrolló empleando el método propuesto en la presente investigación. El mismo depende de la conceptualización definida en una ontología y es extensible por medio de la modificación de la A-Box de la ontología, sin necesidad de modificar el código fuente de la aplicación.

Según \cite{Wohlin2012}, la realización de un caso de estudio involucra cinco grandes pasos por los que transitar:

\begin{enumerate}
\item Diseño del caso de estudio: se definen los objetivos y se planifica el caso de estudio.
\item Preparación para la recolección de los datos: se definen los procedimientos y protocolos para la recolección de los datos.
\item Recolección de los datos: ejecución de la recolección de los datos en el caso estudiado.
\item Análisis de los datos recolectados.
\item Reporte del caso de estudio.
\end{enumerate}

\subsection{Diseño del caso de estudio}
El \textbf{objetivo} del caso de estudio es \textbf{medir qué por ciento de las fuentes de datos, necesarias para el control de autoridades en el proyecto ELINF, es posible integrar mediante el empleo del método propuesto en una aplicación informática}. 

El presente caso de estudio se centra en la escalabilidad en cuanto a fuentes de datos de la aplicación informática AUCTORITAS. Se asume como escalabilidad el concepto elaborado por \cite{duboc2006framework} que la define como la cualidad de las aplicaciones informáticas caracterizada por el impacto causal que poseen aspectos del entorno del sistema según estos son variados por encima de los rangos operacionales.

Las preguntas de investigación que conducirán el presente caso de estudio son:

\begin{enumerate}
\item ¿Qué fuentes de datos de las necesarias para el control de autoridades en el proyecto ELINF es posible integrar con el método propuesto?
\item ¿Qué nivel de flexibilidad aporta la aplicación del método propuesto en el acceso a datos de la aplicación informática AUCTORITAS?
\end{enumerate}

Se definen los siguientes umbrales para la variable flexibilidad:

\begin{itemize}
\item Flexibilidad baja: es necesario modificar el código fuente de la aplicación para adicionar nuevas fuentes de datos y estas deben ser estructuralmente homogéneas.
\item Flexibilidad media: es necesario modificar el código fuente de la aplicación para adicionar nuevas fuentes de datos pero estas pueden ser estructuralmente heterogéneas.
\item Flexibilidad alta: no es necesario modificar el código fuente de la aplicación para adicionar nuevas fuentes de datos y estas pueden ser estructuralmente heterogéneas.
\end{itemize}

El Comité de Expertos del proyecto ELINF identificó como fuentes de datos necesarias para el contro de autoridades las siguientes:

\begin{itemize}
\item Fichero de autoridad local: base de datos que contiene las entradas de autoridad de autores cubanos que no están registrados en fuentes internacionales.
\item VIVO: aplicación informática que gestiona perfiles de investigadores. Esta aplicación se pretende implementar en la red de universidades miembros del proyecto ELINF.
\item ORCID: fuente de datos internacional para la identificación de autores.
\item Tesauro de la ACM: tesauro especializado en Ciencias de la Computación para el control de autoridades a nivel de epígrafes de materia.
\item Tesauro AGROVOC de la FAO: tesauro especializado en Ciencias Agrícolas para el control de autoridades a nivel de epígrafes de materia.
\end{itemize}

\subsection{Recolección de los datos}

De acuerdo con \cite{Lethbridge2005} las técnicas para la recolección de datos se pueden dividir en tres niveles:

\begin{itemize}
\item Primer nivel: Métodos en los que el investigador está en contacto directo con los sujetos y recolecta los datos en tiempo real. 
\item Segundo nivel: Métodos indirectos en los que el investigador recolecta datos en bruto sin interactuar con los sujetos durante la recolección.
\item Tercer nivel: Análisis independiente de artefactos de trabajo donde se utilizan datos disponibles y en algunos casos ya compilados.
\end{itemize}

La técnica para recolectar datos en la presente investigación cae en el tercer nivel, basándose en las investigaciones de \cite{Calzadilla-Reyes2015} y \cite{Gonzalez-Barroso2016}.

El resultado de la recolección de datos se muestra en la tabla \ref{tabla: recoleccion}.

\begin{table}
\centering
\begin{tabular}{c|c|c|c}
\hline 
Aplicación informática & Fuente de datos & Estructura & Modificación código fuente \\ 
\hline 
AUCTORITAS 1.0 & Fichero de autoridad local & Modelo relacional & No\\
\hline
AUCTORITAS 1.0 & VIVO & Servicio REST & Sí\\
\hline
AUCTORITAS 1.0 & ORCID & Servicio REST & Sí\\
\hline
AUCTORITAS 1.0 & Tesauro ACM & Modelo RDF & Sí\\
\hline
AUCTORITAS 1.0 & Tesauro AGROVOC & Modelo RDF & Sí\\
\hline
AUCTORITAS 2.0 & Fichero de autoridad local & Modelo relacional & No\\
\hline
AUCTORITAS 2.0 & VIVO & Servicio REST & No\\
\hline
AUCTORITAS 2.0 & ORCID & Servicio REST & Sí\\
\hline
AUCTORITAS 2.0 & Tesauro ACM & Modelo RDF & No\\
\hline
AUCTORITAS 2.0 & Tesauro AGROVOC & Modelo RDF & No\\
\hline
\end{tabular} 
\caption{Datos recolectados en el caso de estudio.}
\label{tabla: recoleccion}
\end{table}

\subsection{Análisis de los datos recolectados}
El principal objetivo del análisis cualitativo de los datos es llegar a conclusiones a partir de los datos, manteniendo una clara cadena de evidencia \citep{Wohlin2012}. Existen dos partes diferentes de análisis sobre datos cualitativos: las técnicas generadoras de hipótesis y las técnicas para confirmación de hipótesis \citep{799955}. Las técnicas generadoras de hipótesis pretenden arribar a hipótesis a partir de los datos, mientras que las técnicas para confirmación de hipótesis se utilizan para demostrar que una hipótesis es verdadera. El análisis de los datos recolectados en el presente caso de estudio pretenderá demostrar la validez de la hipótesis de la investigación.

El análisis de los datos puede realizarse con diferentes niveles de formalismo, \cite{Wohlin2012} mencionan los siguientes enfoques:

\begin{itemize}
\item Enfoques de inmersión: Son los enfoques menos estructurados, más dependientes de la intuición y las habilidades interpretativas del investigador. Pueden ser difíciles de combinar con los requerimientos para mantener y comunicar la cadena de evidencia.
\item Enfoques de edición: Incluyen pocos códigos pre-elaborados.
\item Enfoques basados en plantillas: Son más formales e incluyen preguntas de investigación creadas a priori.
\item Enfoques quasi-estadísticos: Son altamente formales e incluyen, por ejemplo, cálculos o frecuencias de palabras o frases.
\end{itemize}

El análisis de los datos en el presente caso de estudio utilizará un enfoque basado en plantillas.

La versión 1.0 de la aplicación informática AUCTORITAS fue desarrollada con una clase de acceso a datos, en la cual se gestionaba el acceso a una base de datos relacional conteniendo los registros de autoridades locales. La lógica de acceso a datos estaba atada al consumo de datos a partir de un modelo relacional, por lo que incorporar nuevas fuentes con un modelo de datos diferente provocaba cambios en la lógica de acceso a datos de la aplicación.

El acceso a datos de la versión 2.0 de AUCTORITAS de desarrolló siguiendo el método propuesto en el presente trabajo. La lógica de acceso a datos se hizo dependiente de la parte conceptual de la ontología creada, mientras que las fuentes de datos son configuradas en la instanciación de dicha ontología, constituyendo su A-Box. Esto posibilitó que la integración de nuevas fuentes de datos no produjese cambios en el código fuente de la aplicación excepto en un caso.

En el caso de la fuente de datos ORCID fue necesario modificar el código fuente de la aplicación, debido a que esta fuente utiliza un mecanismo de autenticación OAuth 2.0 que no había sido contemplado en el desarrollo de AUCTORITAS. Teniendo esto en cuenta, se realizó la descripción de la fuente de datos en la instancia de ontología, se incorporó el mecanismo de autenticación a la aplicación y las pruebas resultaron satisfactorias.

La realización del caso de estudio permitió identificar que la versión 1.0 de AUCTORITAS posee una flexibilidad media en su acceso a datos, mientras que la aplicación del método propuesto en el desarrollo de la versión 2.0 aportó un nivel de flexibilidad alto. De igual manera, fue posible verificar que el método propuesto permite integrar el cien por ciento de las fuentes de datos necesarias para el control de autoridades en el proyecto ELINF. Los resultados arrojados por el caso de estudio llevado a cabo comprueban la validez de la hipótesis propuesta en la presente investigación.

\section{Conclusiones del capítulo}

La realización del caso de estudio da lugar a las siguientes conclusiones respecto a la evaluación del método propuesto:

\begin{itemize}
\item La herramienta informática desarrollada como instanciación del método propuesto facilitó la obtención de información requerida para el proceso de  control de autoridades en el proyecto ELINF.
\item La utilización de Integración de Datos Basada en Ontologías, disminuyó el acoplamiento de la herramienta informática desarrollada como instanciación del método propuesto, con la configuración de las fuentes de datos requeridas para el proceso de  control de autoridades en el proyecto ELINF.
\item La instanciación del método propuesto en el acceso a datos de la aplicación informática AUCTORITAS permitió integrar la totalidad de las fuentes de datos requeridas por el proyecto ELINF para el proceso de  control de autoridades.
\end{itemize}