@book{InternationalFederationofLibraryAssociationsandInstitutions2009,
address = {La Haya, Holanda},
author = {{International Federation of Library Associations and Institutions}},
booktitle = {IFLA Series on Bibliographic Control},
editor = {Patton, Glenn},
file = {:D$\backslash$:/Superacion/Doctorado/frad{\_}2013.pdf:pdf},
isbn = {978-3-598-24282-3},
keywords = {Andrew,CATALOGING,Christina,HAGUE (Netherlands),HENGEL-Dietrich,LAVRENOVA,MACEWAN,NETHERLANDS,Olga,PUBLICATIONS},
pages = {13},
publisher = {International Federation of Library Associations and Institutions},
title = {{Functional Requirements for Authority Data: A Conceptual Model}},
volume = {34},
year = {2009}
}

@misc{RealAcademiaEspanola2014,
abstract = {Versi{\'{o}}n electr{\'{o}}nica del Diccionario de la lengua espa{\~{n}}ola, obra lexicogr{\'{a}}fica acad{\'{e}}mica por excelencia.},
author = {{Real Academia Espa{\~{n}}ola}},
booktitle = {Diccionario de la Lengua Espa{\~{n}}ola},
isbn = {9788467041897},
keywords = {Diccionarios,Lengua espa{\~{n}}ola},
title = {{Diccionario de la lengua espa{\~{n}}ola :[Edici{\'{o}}n del Tricentenario]}},
url = {http://dle.rae.es/},
urldate = {2017-12-13},
year = {2014}
}

@article{Tillett2009,
abstract = {Authority control is necessary for meeting the catalog's objectives of enabling users to find the works of an author and to collocate allworks of a person or corporate body. This article looks at the current state of authority control as compared to the visions of the 1979 LITA (Library Information and Technology Association) Institutes and the 1984 Authority Control Interest Group. It explores a new view of IFLA's Universal Bibliographic Control (UBC) and a future vision of a virtual international authority file as a building block for the Semantic Web, and reinforces the importance of authority control to improve the precision of searches of large databases or the Internet.},
author = {Tillett, Barbara B},
doi = {10.1300/J104v38n03_04},
file = {:D$\backslash$:/Superacion/ARTICLES/READED/2009/Tillett - 2009 - Authority Control State of the Art and New Perspectives.pdf:pdf},
issn = {0163-9374},
journal = {Cataloging {\&} Classification Quarterly},
mendeley-groups = {Articles,Authority Control},
number = {3/4},
pages = {23--41},
title = {{Authority Control : State of the Art and New Perspectives}},
volume = {38},
year = {2009}
}
@article{Carrasco2016,
abstract = {Bibliographic collections in traditional libraries often compile records from distributed sources where variable criteria have been applied to the normalization of the data. Furthermore, the source records often follow classical standards, such as MARC21, where a strict normalization of author names is not enforced. The identification of equivalent records in large catalogues is therefore required, for example, when migrating the data to new repositories which apply modern specifications for cataloguing, such as the FRBR and RDA standards. An open-source tool has been implemented to assist authority control in bibliographic catalogues when external features (such as the citations found in scientific articles) are not available for the disambiguation of creator names. This tool is based on similarity measures between the variants of author names combined with a parser which interprets the dates and periods associated with the creator. An efficient data structure (the unigram frequency vector trie) has been used to accelerate the identification of variants. The algorithms employed and the attribute grammar are described in detail and their implementation is distributed as an open-source resource to allow for an easier uptake.},
author = {Carrasco, Rafael C and Serrano, Aureo and Castillo-Buergo, Reydi},
doi = {10.1016/j.ipm.2016.02.002},
file = {:D$\backslash$:/Superacion/ARTICLES/READED/2016/A parser for authority control of author names in bibliographic records.pdf:pdf},
issn = {03064573},
journal = {Information Processing and Management},
keywords = {Cataloguing standards,Digital libraries,Natural language processing},
mendeley-groups = {Authority Control},
number = {5},
pages = {753--764},
publisher = {Elsevier Ltd},
title = {{A parser for authority control of author names in bibliographic records}},
volume = {52},
year = {2016}
}

@article{Sandberg2016,
abstract = {This article suggests that catalogers can provide authority control to authors of journal articles by linking to external international authority databases. It explores the representation of article authors from three disciplines in four databases: International Standard Name Identifier (ISNI), Open Researcher and Contributor ID (ORCID), Scopus, and Virtual International Authority File (VIAF). VIAF and Scopus are particularly promising databases for journal author names, but we believe that a combination of several name databases holds more promise than relying on a single database. We provide examples of RDF links between bibliographic description and author identifiers, including a partial BIBFRAME 2.0 description.},
author = {Sandberg, Jane and Jin, Qiang},
doi = {http://dx.doi.org/10.1080/01639374.2016.1238429},
file = {:D$\backslash$:/Superacion/ARTICLES/READED/2016/How Should Catalogers Provide Authority Control for Journal Article Authors Name Identifiers in the Linked Data World.pdf:pdf},
issn = {0163-9374},
journal = {Cataloging {\&} Classification Quarterly},
keywords = {authority control,bibframe,discovery layers,international authority file,linked data,name authority data,virtual,vocabulary control},
mendeley-groups = {Articles,Authority Control},
number = {8},
pages = {1--16},
title = {{How should Catalogers Provide Authority Control for Journal Article Authors? Name Identifiers in the Linked Data World}},
url = {http://eprints.rclis.org/30155/},
volume = {54},
year = {2016}
}

@article{Harper2007,
abstract = {This article discusses how various controlled vocabularies, classification schemes, and thesauri can serve as some of the building blocks of the Semantic Web. These vocabularies have been developed over the course of decades, and can be put to great use in the development of robust Web services and Semantic Web technologies. The article covers how initial collaboration between the Semantic Web, Library and Metadata communities are creating partnerships to complete work in this area. It then discusses some core principles of authority control before talking more specifically about subject and genre vocabularies and name authority. It is hoped that future systems for internationally shared authority data will link the world's authority data from trusted sources to benefit users worldwide. Finally, the article looks at how encoding and markup of vocabularies can help ensure compatibility with the current and future state of Semantic Web development and provides examples of how this work can help improve the findability and navigation of information on the World Wide Web. [ABSTRACT FROM AUTHOR]},
author = {Harper, Corey A and Tillett, Barbara B},
doi = {http://dx.doi.org/10.1300/J104v43n03_03},
file = {:D$\backslash$:/Superacion/ARTICLES/READED/2007/Harper, Tillett - 2007 - Library of Congress Controlled Vocabularies and Their Application to the Semantic Web.pdf:pdf},
isbn = {0163-9374},
issn = {01639374},
journal = {Cataloging {\&} Classification Quarterly},
mendeley-groups = {Articles},
number = {3/4},
pages = {47--68},
title = {{Library of Congress Controlled Vocabularies and Their Application to the Semantic Web.}},
volume = {43},
year = {2007}
}

@misc{OCLCOnlineComputerLibraryCenterInc.2014,
abstract = {The Virtual International Authority File (VIAF) is an international service designed to provide convenient access to the world's major name authority files. Its creators envision the VIAF as a building block for the Semantic Web to enable switching of the displayed form of names for persons to the preferred language and script of the Web user. VIAF began as a joint project with the Library of Congress (LC), the Deutsche Nationalbibliothek (DNB), the Biblioth{\`{e}}que nationale de France (BNF) and OCLC. It has, over the past decade, become a cooperative effort involving an expanding number of other national libraries and other agencies.},
author = {{Online Computer Library Center Inc.}},
title = {{VIAF}},
url = {http://www.oclc.org/viaf.en.html},
urldate = {2017-12-15},
year = {2017}
}


@misc{ISNIInternationalStandardNameIdentifier2017,
author = {{ISNI International Standard Name Identifier}},
title = {{ISNI}},
url = {http://www.isni.org/},
urldate = {2017-12-15},
year = {2017}
}

@misc{ORCID2017,
author = {ORCID},
title = {{ORCID | Connecting Research and Researchers}},
url = {https://orcid.org/},
urldate = {2017-12-15},
year = {2017}
}

@misc{Elsevier2016,
abstract = {Scopus is the largest abstract and citation database of peer-reviewed literature: scientific journals, books and conference proceedings. Delivering a comprehensive overview of the world's research output in the fields of science, technology, medicine, social sciences, and arts and humanities, Scopus features smart tools to track, analyze and visualize research. As research becomes increasingly global, interdisciplinary and collaborative, you can make sure that critical research from around the world is not missed when you choose Scopus.},
author = {Elsevier},
title = {{Scopus}},
url = {https://www.elsevier.com/solutions/scopus},
year = {2016}
}

@article{Lacasta2013,
author = {Lacasta, Javier and Nogueras-Iso, Javier and Falquet, Gilles and Teller, Jacques and Zarazaga-soria, F Javier},
doi = {10.1016/j.datak.2013.10.001},
file = {:D$\backslash$:/Superacion/ARTICLES/READED/2013/1-s2.0-S0169023X13001067-main.pdf:pdf},
issn = {0169-023X},
journal = {Data {\&} Knowledge Engineering},
keywords = {Data and knowledge visualization,Digital libraries,Ontologies,Semantic Web},
mendeley-groups = {Articles},
number = {1},
pages = {94--107},
publisher = {Elsevier B.V.},
title = {{Design and evaluation of a semantic enrichment process for bibliographic databases}},
url = {http://dx.doi.org/10.1016/j.datak.2013.10.001},
volume = {88},
year = {2013}
}

@article{Vavliakis2013,
abstract = {A necessary step for the evolution of the traditional Web into a Semantic Web is the transformation of the vast quantities of data, currently residing in Relational Databases into semantically aware data. In addition, in cases where new ontology schemata are developed, considerable experimentation with real data for testing the consistency of classes, properties and entailment rules is required. During the last decade, there has been intense research and development in creating methodologies and tools able to map Relational Databases with the Resource Description Framework (RDF). Although some systems have gained wider acceptance in the Semantic Web community, they either require users to learn a declarative language for encoding mappings or, in case they support friendly user interfaces, they provide limited expressivity. Thereupon, we present RDOTE, a framework for easily transporting data residing in Relational Databases into the Semantic Web. RDOTE is available under GNU/GPL license and it provides friendly graphical user interfaces, as well as enough expressivity for creating automatic and custom RDF dumps of relational data. RDOTE is also compatible with D2RQ and R2RML mapping definitions. {\textcopyright} 2012 Elsevier Inc. All rights reserved.},
author = {Vavliakis, Konstantinos N. and Grollios, Theofanis K. and Mitkas, Pericles A.},
doi = {10.1016/j.jss.2012.07.018},
file = {:D$\backslash$:/Superacion/ARTICLES/Organizados/Vavliakis, Grollios, Mitkas/Vavliakis, Grollios, Mitkas - 2013 - RDOTE - Publishing Relational Databases into the Semantic Web.pdf:pdf},
isbn = {0164-1212},
issn = {01641212},
journal = {Journal of Systems and Software},
keywords = {D2RQ,R2RML,RDB2RDF,RDF dump,Relational Databases to ontology transformation},
number = {1},
pages = {89--99},
publisher = {Elsevier Inc.},
title = {{RDOTE - Publishing relational databases into the semantic web}},
volume = {86},
year = {2013}
}

@article{Gutierrez2011,
abstract = {The Semantic Web is based on the idea of a common and minimal language to enable large quantities of existing data to be analyzed and processed. This triggers the need to develop the database foundations of this basic language, which is the Resource Description Framework (RDF). This paper addresses this challenge by: 1) developing an abstract model and query language suitable to formalize and prove properties about the RDF data and query language; 2) studying the RDF data model, minimal and maximal representations, as well as normal forms; 3) studying systematically the complexity of entailment in the model, and proving complexity bounds for the main problems; 4) studying the notions of query answering and containment arising in the RDF data model; and 5) proving complexity bounds for query answering and query containment. {\textcopyright} 2010 Elsevier Inc. All rights reserved.},
author = {Gutierrez, Claudio and Hurtado, Carlos A. and Mendelzon, Alberto O. and P{\'{e}}rez, Jorge},
doi = {10.1016/j.jcss.2010.04.009},
file = {:D$\backslash$:/Superacion/ARTICLES/Organizados/Gutierrez et al/Gutierrez et al. - 2011 - Foundations of Semantic Web databases.pdf:pdf},
isbn = {158113858X},
issn = {00220000},
journal = {Journal of Computer and System Sciences},
keywords = {Query language,RDF model,Semantic Web},
number = {3},
pages = {520--541},
title = {{Foundations of Semantic Web databases}},
volume = {77},
year = {2011}
}

@book{maier1983theory,
address = {Rockville, MD},
author = {Maier, David},
publisher = {Computer science press Rockville},
title = {{The theory of relational databases}},
year = {1983}
}

@inproceedings{Shanmugasundaram1999,
abstract = {Note: OCR errors may be found in this Reference List extracted from the full text article. ACM has opted to expose the complete List rather than only correct and linked references.},
address = {San Francisco, CA},
author = {Shanmugasundaram, Jayavel and Tufte, Kristin and He, Gang and Zhang, Chun and DeWitt, David J and Naughton, Jeffrey F and He, Gang and DeWitt, David J and Naughton, Jeffrey F},
booktitle = {Proceedings of the 25th VLDB Conference,},
doi = {10.1016/j.acalib.2005.12.008},
editor = {Atkinson, Malcolm P. and Orlowska, Maria E. and Valduriez, Patrick and Zdonick, Stanley B. and Brodie, Michael L.},
isbn = {1558606157},
issn = {0099-1333},
pages = {302--314},
publisher = {Morgan Kaufmann Publishers Inc.},
title = {{Relational databases for querying XML documents: Limitations and opportunities.}},
year = {1999}
}

@article{Ilyas2004,
abstract = {Ranking queries, also known as top-k queries, produce results that are ordered on some computed score. Typically, these queries involve joins, where users are usually interested only in the top-k join results. Top-k queries are dominant in many emerging applications, e.g., multimedia retrieval by content,Web databases, data mining, middlewares, and most information retrieval applications. Current relational query processors do not handle ranking queries efficiently, especially when joins are involved. In this paper, we address supporting top-k join queries in relational query processors. We introduce a new rank-join algorithm that makes use of the individual orders of its inputs to produce join results ordered on a user-specified scoring function. The idea is to rank the join results progressively during the join operation.We introduce two physical query operators based on variants of ripple join that implement the rank-join algorithm. The operators are nonblocking and can be integrated into pipelined execution plans.We also propose an efficient heuristic designed to optimize a top-k join query by choosing the best join order.We address several practical issues and optimization heuristics to integrate the new join operators in practical query processors. We implement the new operators inside a prototype database engine based on PREDATOR. The experimental evaluation of our approach compares recent algorithms for joining ranked inputs and shows superior performance.},
author = {Ilyas, Ihab F. and Aref, Walid G. and Elmagarmid, Ahmed K.},
doi = {10.1007/s00778-004-0128-2},
issn = {10668888},
journal = {VLDB Journal},
keywords = {Query operators,Ranking,Top-k queriesrank aggregation},
number = {3},
pages = {207--221},
title = {{Supporting top-k join queries in relational databases}},
volume = {13},
year = {2004}
}

@article{Spanos2012,
abstract = {Relational databases are considered one of the most popular storage solutions for various kinds of data and they have been recognized as a key factor in generating huge amounts of data for Semantic Web applications. Ontologies, on the other hand, are one of the key concepts and main vehicle of knowledge in the Semantic Web research area. The problem of bridging the gap between relational databases and ontologies has attracted the interest of the Semantic Web community, even from the early years of its existence and is commonly referred to as the database-to-ontology mapping problem. However, this term has been used interchangeably for referring to two distinct problems: namely, the creation of an ontology from an existing database instance and the discovery of mappings between an existing database instance and an existing ontology. In this paper, we clearly define these two problems and present the motivation, benefits, challenges and solutions for each one of them. We attempt to gather the most notable approaches proposed so far in the literature, present them concisely in tabular format and group them under a classification scheme. We finally explore the perspectives and future research steps for a seamless and meaningful integration of databases into the Semantic Web.},
author = {Spanos, Dimitrios-Emmanuel and Stavrou, Periklis and Mitrou, Nikolas},
doi = {10.3233/SW-2011-0055},
file = {:D$\backslash$:/Superacion/ARTICLES/POR LEER/1er nivel/Bringing relational databases into the semantic web - A survey.pdf:pdf},
isbn = {1570-0844},
issn = {1570-0844},
journal = {Semantic Web},
keywords = {mapping,ontology,owl,relational database,survey},
number = {2},
pages = {169--209},
title = {{Bringing relational databases into the Semantic Web: A survey}},
url = {http://www.semantic-web-journal.net/sites/default/files/swj121_1.pdf},
volume = {3},
year = {2012}
}

@article{Pokorny2013,
abstract = {The paper is focused on so called NoSQL databases. In context of cloud computing, architectures and basic features of these databases are studied, particularly their horizontal scalability and concurrency model, that is mostly weaker than ACID transactions in relational SQL-like database systems. Some characteristics like a data model and querying capabilities are discussed in more detail. The paper also contains an overview of some representatives of NoSQL databases.},
author = {Pokorny, Jaroslav},
doi = {10.1108/17440081311316398},
file = {:D$\backslash$:/Superacion/ARTICLES/Organizados/Pokorny/Pokorny - 2013 - NoSQL databases a step to database scalability in web environment.pdf:pdf},
issn = {1744-0084},
journal = {International Journal of Web Information Systems},
number = {1},
pages = {69--82},
title = {{NoSQL databases: a step to database scalability in web environment}},
url = {http://dl.acm.org/citation.cfm?doid=2095536.2095583},
volume = {9},
year = {2013}
}

@article{Moniruzzaman2013,
abstract = {Abstract: Digital world is growing very fast and become more complex in the volume (terabyte to petabyte), variety (structured and un-structured and hybrid), velocity (high speed in growth) in nature. This refers to as Big Data that is a global phenomenon. This is ...},
author = {Moniruzzaman, A B M and Hossain, Syed Akhter},
file = {:D$\backslash$:/Superacion/ARTICLES/Organizados/Moniruzzaman, Hossain/Moniruzzaman, Hossain - 2013 - Nosql database New era of databases for big data analytics-classification, characteristics and comparison.pdf:pdf},
issn = {2207-9688},
journal = {International Journal of Database Theory and Application},
keywords = {big data,big data analytics,newsql database,nosql database},
number = {4},
pages = {1--14},
title = {{Nosql database: New era of databases for big data analytics-classification, characteristics and comparison}},
volume = {6},
year = {2013}
}

@article{Berners-Lee2001,
abstract = {A new form of Web content that is meaningful to computers will unleash a revolution of new possibilities.},
archivePrefix = {arXiv},
arxivId = {1204.6441},
author = {Berners-Lee, Tim and Hendler, James and Lassila, Ora},
doi = {10.1038/scientificamerican0501-34},
eprint = {1204.6441},
isbn = {9783540762973},
issn = {0036-8733},
journal = {Scientific American},
number = {5},
pages = {34--43},
pmid = {122},
title = {{The Semantic Web}},
volume = {284},
year = {2001}
}

@article{Konstantinou2014,
abstract = {The Linked Open Data (LOD) movement is constantly gaining worldwide acceptance. In this paper we describe how LOD is generated in the case of digital repositories that contain bibliographic information, adopting international standards. The available options and respective choices are presented and justified while we also provide a technical description, the methodology we followed, the possibilities and difficulties in the way, and the respective benefits and drawbacks. Detailed examples are provided regarding the implementation and query capabilities, and the paper concludes after a discussion over the results and the challenges associated with our approach, and our most important observations and future plans.},
author = {Konstantinou, Nikolaos and Houssos, Nikos and Manta, Anastasia},
doi = {10.1016/j.sbspro.2014.07.169},
file = {:D$\backslash$:/Superacion/ARTICLES/Organizados/Konstantinou, Houssos, Manta/Konstantinou, Houssos, Manta - 2014 - Exposing Bibliographic Information as Linked Open Data using Standards-based Mappings Methodology.pdf:pdf},
issn = {18770428},
journal = {Procedia - Social and Behavioral Sciences},
keywords = {Linked Open Data,R2RML,RDF,SPARQL Endpoint,bibliographic information,databases,mapping,ontology,repositories},
number = {1},
pages = {260--267},
publisher = {Elsevier B.V.},
title = {{Exposing Bibliographic Information as Linked Open Data Using Standards-based Mappings: Methodology and Results}},
url = {http://www.sciencedirect.com/science/article/pii/S1877042814040889},
volume = {147},
year = {2014}
}

@article{Sule2016,
abstract = {This article discusses how and to what extent the RDF data model is applied in major Spanish digital collections of heritage materials. This model, as well as Open Data and Linked Data initiatives, are introduced. Fifty-one digital repositories were analysed to determine whether they expressed their records in RDF, offered SPARQL query points searchable by external agents, and used references as property values. The Europeana EDM and OntoWeb models are also described. It is concluded that the use of RDF is unequal and excessively conditioned by the use of applications that automatically convert records into RDF triples. Few of the collections analysed give SPARQL points for external queries. Also, the use of references is linked to applications using different models: EDM or OntoWeb. Collections should enrich their data and define aggregation levels for generated RDF data in order to be disseminated, made accessible, and adapted to the semantic web.},
author = {Sul{\'{e}}, Andreu and Centelles, Miquel and Franganillo, Jorge and Gasc{\'{o}}n, Jes{\'{u}}s},
doi = {10.3989/redc.2016.1.1268},
file = {:D$\backslash$:/Superacion/ARTICLES/Organizados/Sul{\'{e}} et al/Sul{\'{e}} et al. - 2016 - Aplicaci{\'{o}}n del modelo de datos RDF en las colecciones digitales de bibliotecas, archivos y museos de Espa{\~{n}}a.pdf:pdf},
isbn = {1988-4621},
issn = {0210-0614},
journal = {Revista espa{\~{n}}ola de Documentaci{\'{o}}n Cient{\'{i}}fica},
keywords = {Europeana Data Model,OntoWeb,RDF,SPARQL query,URI,abstract,and to what extent,archives and museums,collections of spanish libraries,consulta SPARQL,consulta sparql,data model,data model in digital,data models,datos abiertos,datos enlazados,europeana,heritage repositories,implementation of the rdf,is applied in major,linked data,modelos de datos,ontoweb,open data,rdf,references,referencias,repositorios patrimoniales,spanish digital collections,the article discusses how,the rdf data model,uri},
number = {1},
pages = {121--139},
title = {{Aplicaci{\'{o}}n del modelo de datos RDF en las colecciones digitales de bibliotecas, archivos y museos de Espa{\~{n}}a}},
url = {http://redc.revistas.csic.es/index.php/redc/article/view/924/1340},
volume = {39},
year = {2016}
}
@inproceedings{duboc2006framework,
author = {Duboc, Leticia and Rosenblum, David S and Wicks, Tony},
booktitle = {Proceedings of the 28th international conference on Software engineering},
file = {:D$\backslash$:/Superacion/ARTICLES/POR LEER/Escalabilidad de software/4990.pdf:pdf},
organization = {ACM},
pages = {949--952},
title = {{A framework for modelling and analysis of software systems scalability}},
year = {2006}
}
@inproceedings{Offermann2010,
address = {St. Gallen},
author = {Offermann, Philipp and Blom, S{\"{o}}ren and Sch{\"{o}}nherr, Marten and Bub, Udo},
booktitle = {Global perspectives on design science research},
doi = {https://doi.org/10.1007/978-3-642-13335-0},
editor = {Winter, Robert and {Leon Zhao J.} and Aier, Stephan},
file = {:D$\backslash$:/Superacion/Doctorado/Conferencia IT Artifacts/it artifacts/AlejandroRosete/Tipos de IT Artifacto 2010.pdf:pdf},
keywords = {design science,it artifact,literature review,research output,typology},
pages = {77--92},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{Artifact Types in Information Systems Design Science – A Literature Review}},
url = {https://link.springer.com/book/10.1007/978-3-642-13335-0{\#}toc},
year = {2010}
}
@article{Janev2011,
abstract = {The Semantic Web is one of the fastest developing fields within the Information and Communication Technology sector and, as such, under constant examination by scientists and IT professionals. This article aims to provide a better understanding of the applicability of Semantic Web tools and technologies in practice. This aim will be achieved by surveying the recommended and emerging W3C standards, presenting an overview of the state-of-the-art in the Semantic Web research in the European Union, analysing the W3C collection of Case studies and Use Cases, and discussing the extent of adoption of Semantic Web technologies. The overall technology maturity level assessment has shown that Semantic Web technologies are finding their ways into real-world applications, and that, rather than being merely a fashionable research issue, the Semantic Web, slowly but surely, becomes our reality. ?? 2010 Elsevier Ltd. All rights reserved.},
author = {Janev, Valentina and Vranes, Sanja},
doi = {10.1016/j.ipm.2010.11.002},
file = {:D$\backslash$:/Superacion/ARTICLES/READED/2011/1-s2.0-S0306457310000920-main.pdf:pdf},
isbn = {0306-4573},
issn = {03064573},
journal = {Information Processing and Management},
keywords = {Adoption,Applicability,Applications,Assessment,Industry,Semantic Web technologies,W3C},
mendeley-groups = {Articles},
number = {4},
pages = {507--517},
publisher = {Elsevier Ltd},
title = {{Applicability assessment of Semantic Web technologies}},
volume = {47},
year = {2011}
}
@inproceedings{Han2005,
abstract = {Because of name variations, an author may have multiple names and multiple authors may share the same name. Such name ambiguity affects the performance of document retrieval, web search, database integration, and may cause improper attribution to authors. This paper presents a hierarchical naive Bayes mixture model, an unsupervised learning approach, for name disambiguation in author citations. This method partitions a collection of citations1 into clusters, with each cluster containing only citations authored by the same author, thus disambiguating authorship in citations to induce author name identities. Three types of citation features are used: co-author names, paper title words, and journal or proceeding title words. The approach is illustrated with 16 name datasets that are constructed based on the publication lists collected from author homepages and DBLP computer science bibliography.},
address = {New Mexico},
author = {Han, Hui and Xu, Wei and Zha, Hongyuan and Giles, C. Lee},
booktitle = {Proceedings of the 2005 ACM symposium on Applied computing - SAC '05},
doi = {10.1145/1066677.1066920},
file = {:D$\backslash$:/Superacion/ARTICLES/READED/2005/A Hierarchical Na{\"{i}}ve Bayes Mixture Model for Name Disambiguation in Author Citations.pdf:pdf},
isbn = {1581139640},
keywords = {feature selection,name disambiguation,unsupervised learning},
mendeley-groups = {Articles},
pages = {1065--1069},
publisher = {ACM},
title = {{A hierarchical naive Bayes mixture model for name disambiguation in author citations}},
year = {2005}
}
@article{Nachouki2011,
abstract = {This paper describes a process for mashing heterogeneous data sources based on the Multi-data source Fusion Approach (MFA) (Nachouki and Quafafou, 2008 [52]). The aim of MFA is to facilitate the fusion of heterogeneous data sources in dynamic contexts such as the Web. Data sources are either static or active: static data sources can be structured or semi-structured (e.g. XML documents or databases), whereas active sources are services (e.g. Web services). Our main objective is to combine (Web) data sources with a minimal effort required from the user. This objective is crucial because the mashing process implies easy and fast integration of data sources. We suppose that the user is not expert in this field but he/she understands the meaning of data being integrated. In this paper, we consider two important aspects of the Web mashing process. The first one concerns the information extraction from the Web. The results of this process are the static data sources that are used later together with services in order to create a new result/application. The second one concerns the problem of semantic reconciliation of data sources. This step consists to generate the Conflicts data source in order to improve the problem of rewriting semantic queries into sub-queries (not addressed in this paper) over data sources. We give the design of our system MDSManager. We show this process through a real-life application. ?? 2010 Elsevier B.V. All rights reserved.},
author = {Nachouki, Gilles and Quafafou, Mohamed},
doi = {10.1016/j.is.2010.08.001},
file = {:D$\backslash$:/Superacion/ARTICLES/READED/2011/1-s2.0-S0306437910000785-main.pdf:pdf},
issn = {03064379},
journal = {Information Systems},
keywords = {Conflicts detection,Information extraction,MashUp,Multi-data sources,Semantic queries},
mendeley-groups = {Articles},
number = {2},
pages = {151--173},
publisher = {Elsevier},
title = {{MashUp web data sources and services based on semantic queries}},
url = {http://www.elsevier.com/locate/infosys},
volume = {36},
year = {2011}
}
@article{Sheth1990,
abstract = {A federated database system (FDBS) is a collection of cooperating database systems that are autonomous and possibly heterogeneous. In this paper, we define a reference architecture for distributed database management systems from system and schema viewpoints and show how various FDBS architectures can be developed. We then define a methodology for developing one of the popular architectures of an FDBS. Finally, we discuss critical issues related to developing and operating an FDBS.},
author = {Sheth, Amit P. and Larson, James A.},
doi = {10.1145/96602.96604},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Tesis/Bibliograf{\'{i}}a/Data integration/p183-sheth.pdf:pdf},
isbn = {0360-0300},
issn = {03600300},
journal = {ACM Computing Surveys},
number = {3},
pages = {183--236},
pmid = {120},
title = {{Federated database systems for managing distributed, heterogeneous, and autonomous databases}},
url = {http://portal.acm.org/citation.cfm?doid=96602.96604},
volume = {22},
year = {1990}
}

@article{Calvanese2016,
annote = {Mining the Humanities: Technologies and Applications},
author = {Calvanese, Diego and Liuzzo, Pietro and Mosca, Alessandro and Remesal, Jos{\'{e}} and Rezk, Martin and Rull, Guillem},
doi = {https://doi.org/10.1016/j.engappai.2016.01.005},
file = {:D$\backslash$:/Superacion/ARTICLES/POR LEER/Ontology-based data access/Ontology-based data integration in EPNet - Production and distribution of food during the Roman Empire.pdf:pdf},
issn = {0952-1976},
journal = {Engineering Applications of Artificial Intelligence},
keywords = {E-Culture,EPNet,Knowledge Representation and Reasoning,Ontology-Based Data Access,Ontology-Based Data Integration,Ontop},
pages = {212--229},
title = {{Ontology-based data integration in EPNet: Production and distribution of food during the Roman Empire}},
url = {http://www.sciencedirect.com/science/article/pii/S0952197616000099},
volume = {51},
year = {2016}
}
@inbook{Calvanese2017,
address = {New York, NY},
author = {Calvanese, Diego and {De Giacomo}, Giuseppe and Lembo, Domenico and Lenzerini, Maurizio and Rosati, Riccardo},
booktitle = {Encyclopedia of Database Systems},
doi = {10.1007/978-1-4899-7993-3_80667-1},
editor = {Liu, Ling and {\"{O}}zsu, M Tamer},
file = {:D$\backslash$:/Superacion/ARTICLES/POR LEER/Ontology-based data access/OBDA and Integration.pdf:pdf},
isbn = {978-1-4899-7993-3},
pages = {1--7},
publisher = {Springer New York},
title = {{Ontology-Based Data Access and Integration}},
url = {https://doi.org/10.1007/978-1-4899-7993-3{\_}80667-1},
year = {2017}
}
@article{ElKadiri2015,
author = {{El Kadiri}, Soumaya and Grabot, Bernard and Thoben, Klaus-dieter and Hribernik, Karl and Emmanouilidis, Christos and {Von Cieminski}, Gregor and Kiritsis, Dimitris},
doi = {10.1016/j.compind.2015.06.008},
file = {:D$\backslash$:/Superacion/ARTICLES/POR LEER/Data Integration/1-s2.0-S0166361515300142-main.pdf:pdf},
issn = {0166-3615},
journal = {Computers in Industry},
keywords = {enterprise information system},
publisher = {Elsevier B.V.},
title = {{Current trends on ICT technologies for enterprise information}},
year = {2015}
}
@article{McGinnes2015,
author = {McGinnes, Simon and Kapros, Evangelos},
doi = {10.1016/j.is.2014.06.001},
file = {:D$\backslash$:/Superacion/ARTICLES/READED/2015/1-s2.0-S0306437914000933-main.pdf:pdf},
issn = {0306-4379},
journal = {Information Systems},
keywords = {Adaptive information systems,Conceptual independence,Conceptual modelling,Data independence,Schema evolution,Software design,conceptual independence,conceptual modelling},
mendeley-groups = {Articles},
pages = {33--50},
publisher = {Elsevier},
title = {{Conceptual independence: A design principle for the construction of adaptive information systems}},
volume = {47},
year = {2015}
}
@article{Franke2014,
author = {Franke, Marco and Klein, Konstantin and Hribernik, Karl and Lappe, Dennis and Veigt, Marius and Thoben, Klaus-dieter},
doi = {10.1016/j.procir.2014.07.020},
file = {:D$\backslash$:/Superacion/ARTICLES/POR LEER/Data Integration/1-s2.0-S2212827114008336-main.pdf:pdf},
issn = {2212-8271},
journal = {Procedia CIRP},
keywords = {data integration,product lifeycle management,semantic data integration},
pages = {225--230},
publisher = {Elsevier B.V.},
title = {{Semantic Web Service Wrappers as a foundation for interoperability in closed-loop Product Lifecycle Management}},
volume = {22},
year = {2014}
}
@article{Hoang2014,
author = {Hoang, Hanh Huu and Cung, Tai Nguyen-phuoc and Truong, Duy Khanh and Hwang, Dosam and Jung, Jason J},
doi = {10.1155/2014/813875},
file = {:D$\backslash$:/Superacion/ARTICLES/POR LEER/Data Integration/813875.pdf:pdf},
journal = {International Journal of Distributed Sensor Networks},
title = {{Semantic Information Integration with Linked Data Mashups Approaches}},
year = {2014}
}
@article{Leiva-Mederos2013,
author = {Leiva-Mederos, Amed and Senso, Jos{\'{e}} A. and Dom{\'{i}}nguez-Velasco, Sandor and H{\'{i}}pola, Pedro},
doi = {10.1108/LHT-12-20112-0135},
file = {:D$\backslash$:/Superacion/ARTICLES/READED/2013/AUTHORIS{\_}a{\_}tool{\_}for{\_}authority{\_}control{\_}in{\_}the{\_}Semantic{\_}Web.pdf:pdf},
journal = {Library Hi Tech},
keywords = {Cataloguing,Data management,Interoperability,Linked data,Records exchange,Semantic web,authority control software},
mendeley-groups = {Articles},
number = {3},
pages = {536--553},
title = {{AUTHORIS: a tool for authority control in the semantic web}},
volume = {31},
year = {2013}
}
@book{cutter1889rules,
  title={Rules for a printed dictionary catalogue},
  author={Cutter, Charles Ammi},
  year={1889},
  publisher={US Government Printing Office}
}
@book{lubetzky1969principles,
  title={The Principles of Cataloging: Report},
  author={Lubetzky, Seymour and Hayes, Robert Mayo},
  year={1969},
  publisher={Institute of Library Research, University of California}
}
@article{bregzis1982syndetic,
  title={The syndetic structure of the catalog},
  author={Bregzis, Ritvars},
  journal={Authority control: the key to tomorrow’s catalog. Proceedings of the 1979 Library and Information Technology Association Institute, Mary W. Ghikas ed. Phoenix: AZ},
  year={1982}
}

@misc{Berners-Lee2006,
author = {Berners-Lee, Tim},
file = {:D$\backslash$:/Superacion/ARTICLES/Organizados/Berners-lee/Berners-Lee - 2006 - Linked Data.pdf:pdf},
pages = {1--7},
title = {{Linked Data}},
url = {http://www.w3.org/DesignIssues/LinkedData.html},
urldate = {12/28/2017},
year = {2006}
}


@article{motik2009bridging,
  title={Bridging the gap between OWL and relational databases},
  author={Motik, Boris and Horrocks, Ian and Sattler, Ulrike},
  journal={Web Semantics: Science, Services and Agents on the World Wide Web},
  volume={7},
  number={2},
  pages={74--89},
  year={2009},
  publisher={Elsevier}
}

@article{Horrocks,
author = {Ian Horrocks, Peter F. Patel-Schneider and Frank van Harmelen},
journal = {Web Semantics},
language = {English},
number = {1},
pages = {7--26},
title = {{From SHIQ and RDF to OWL: The Making of a Web Ontology Language}},
volume = {1},
year = 2003}
}

@article{Studer1998,
archivePrefix = {arXiv},
arxivId = {1107.3326},
author = {Studer, Rudy and {Richards Benjamins}, V. and Fensel, Dieter},
doi = {10.1016/S0169-023X(97)00056-6},
eprint = {1107.3326},
file = {:D$\backslash$:/Superacion/ARTICLES/READED/1998/Knowledge engineering - principles and methods.pdf:pdf},
isbn = {9780306485749},
issn = {0169023X},
journal = {Data {\&} Knowledge Engineering},
keywords = {information integration,knowledge acquisition,knowledge engineering,of social science informatics,ontology,problem-solving method,swi},
mendeley-groups = {Articles},
number = {1-2},
pages = {161--197},
pmid = {20116780},
title = {{Knowledge engineering: Principles and methods}},
volume = {25},
year = {1998}
}

@article{Munir,
author = {K. Munir, M. Odeh and R. McClatchey},
journal = {Knowledge-based Systems},
language = {English},
pages = {144--159},
title = {{Ontology-driven relational query formulation using the semantic and assertional capabilities of OWL-DL}},
volume = {35},
year = 2012}
}

@article{Agus,
author = {H. Agus-Santoso, S. Cheng-Haw and Z. Abdul-Mehdi},
journal = {Knowledge-based Systems},
language = {English},
number = {3},
pages = {457--464},
title = {{Ontology extraction from relational database: Concept hierarchy as background knowledge}},
volume = {24},
year = 2011}
}

@misc{Masinter2005,
author = {Masinter, Larry and Berners-Lee, Tim and Fielding, Roy T.},
title = {{Uniform Resource Identifier}},
url = {http://tools.ietf.org/html/rfc3986},
urldate = {12/28/2017},
year = {2005}
}

@phdthesis{Hidalgo-Delgado2015,
author = {Hidalgo-Delgado, Yusniel},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Ejemplos tesis/TM-2015-Yusniel Hidalgo Delgado.pdf:pdf},
school = {Universidad de las Ciencias Inform{\'{a}}ticas},
title = {{Marco de trabajo basado en los datos enlazados para la interoperabilidad sem{\'{a}}ntica en el protocolo OAI-PMH}},
type = {Tesis de maestr{\'{i}}a},
year = {2015}
}


@book{Heath2011,
author = {Heath, Tom and Bizer, Christian},
doi = {10.2200/S00334ED1V01Y201102WBE001},
edition = {1},
editor = {Hendler, James},
file = {:D$\backslash$:/Superacion/ARTICLES/Organizados/Heath, Bizer/Heath, Bizer - 2011 - Linked Data Evolving theWeb into a Global Data Space.pdf:pdf},
isbn = {9781608454303},
publisher = {Morgan {\&} Claypool},
title = {{Linked Data. Evolving the Web into a Global Data Space}},
year = {2011}
}

@misc{Klyne2004,
author = {Klyne, Graham and Caroll, Jeremy J.},
title = {{Resource Description Framework (RDF): Concepts and Abstract Syntax}},
url = {http://www.w3.org/TR/rdf-concepts/},
urldate = {2017/12/28},
year = {2004}
}

@article{Gruber1993,
abstract = {To support the sharing and reuse of formally represented knowledge among AI systems, it is useful to define the common vocabulary in which shared knowledge is represented. A specification of a representational vocabulary for a shared domain of discourse—definitions of classes, relations, functions, and other objects—is called an ontology. This paper describes a mechanism for defining ontologies that are portable over representation systems. Definitions written in a standard format for predicate calculus are translated by a system called Ontolingua into specialized representations, including frame-based systems as well as relational languages. This allows researchers to share and reuse ontologies, while retaining the computational benefits of specialized implementations. We discuss how the translation approach to portability addresses several technical problems. One problem is how to accommodate the stylistic and organizational differences among representations while preserving declarative content. Another is how to translate from a very expressive language into restricted languages, remaining system-independent while preserving the computational efficiency of implemented systems. We describe how these problems are addressed by basing Ontolingua itself on an ontology of domain-independent, representational idioms.},
author = {Gruber, Thomas R.},
doi = {10.1006/knac.1993.1008},
file = {:D$\backslash$:/Superacion/ARTICLES/READED/1993/Gruber - 1993 - A translation approach to portable ontology specifications.pdf:pdf},
isbn = {1042-8143},
issn = {10428143},
journal = {Knowledge Acquisition},
number = {2},
pages = {199--220},
pmid = {21685580},
title = {{A translation approach to portable ontology specifications}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1042814383710083},
volume = {5},
year = {1993}
}

@book{Staab2009,
address = {New York, NY},
doi = {10.1007/978-3-540-92673-3},
edition = {2},
editor = {Staab, Steffen and Studer, Rudi},
file = {:D$\backslash$:/Superacion/INVESTIGACI{\'{O}}N/Documentaci{\'{o}}n/Web sem{\'{a}}ntica/books/Handbook{\_}on{\_}Ontologies{\_}SE{\_}-{\_}S.Staab{\_}R.Studer.PDF:PDF},
isbn = {978-3-540-70999-2},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{Handbook on Ontologies}},
year = {2009}
}

@book{Gomez-Perez2004,
address = {Londres},
author = {G{\'{o}}mez-P{\'{e}}rez, Asunci{\'{o}}n and Fern{\'{a}}ndez-L{\'{o}}pez, Mariano and Corcho, Oscar},
edition = {1},
editor = {Wu, Xindong and Jain, Lakhmi},
file = {:D$\backslash$:/Superacion/INVESTIGACI{\'{O}}N/Documentaci{\'{o}}n/Web sem{\'{a}}ntica/books/Ontological Engineering.pdf:pdf},
isbn = {1-85233-551-3},
publisher = {Springer-Verlag London},
title = {{Ontological Engineering}},
year = {2004}
}

@article{Iqbal2013,
author = {Iqbal, Rizwan and Azrifah, Masrah and Murad, Azmi and Mustapha, Aida and Sharef, Nurfadhlina Mohd},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Cursos/Redes Avanzadas/Trabajo Final/Bibliograf{\'{i}}a/An{\_}analysis{\_}of{\_}ontology{\_}engineering{\_}meth.pdf:pdf},
issn = {2040-7459},
journal = {Research Journal of Applied Sciences, Engineering and Technology},
keywords = {knowledge engineering,ontologies,ontology engineering,semantic web},
number = {16},
pages = {2993--3000},
title = {{An Analysis of Ontology Engineering Methodologies : A Literature Review}},
volume = {6},
year = {2013}
}

@misc{AloomaInc.2017,
author = {{Alooma Inc.}},
booktitle = {ETL Enterprise Data Integration},
title = {{ETL software tools}},
url = {https://www.etltools.net/},
urldate = {2018-01-15},
year = {2017}
}

@phdthesis{Michel2017,
author = {Michel, Franck},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Tesis/Bibliograf{\'{i}}a/Data integration/FranckMichel-PhD.pdf:pdf},
keywords = {Data Integration,MongoDB,SPARQL,Web of Data,legacy data,virtual RDF store,xR2RML},
school = {C{\^{o}}te D'Azur},
title = {{Integrating Heterogeneous Data Sources in the Web of Data}},
type = {Tesis Doctoral},
year = {2017}
}

@book{Doan:2012:PDI:2401764,
 author = {Doan, AnHai and Halevy, Alon and Ives, Zachary},
 title = {Principles of Data Integration},
 year = {2012},
 isbn = {0124160441, 9780124160446},
 edition = {1st},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
}

@inproceedings{Lenzerini:2002:DIT:543613.543644,
 author = {Lenzerini, Maurizio},
 title = {Data Integration: A Theoretical Perspective},
 booktitle = {Proceedings of the Twenty-first ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems},
 series = {PODS '02},
 year = {2002},
 isbn = {1-58113-507-6},
 location = {Madison, Wisconsin},
 pages = {233--246},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/543613.543644},
 doi = {10.1145/543613.543644},
 acmid = {543644},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@InProceedings{Schwarte2011,
author="Schwarte, Andreas
and Haase, Peter
and Hose, Katja
and Schenkel, Ralf
and Schmidt, Michael",
editor="Aroyo, Lora
and Welty, Chris
and Alani, Harith
and Taylor, Jamie
and Bernstein, Abraham
and Kagal, Lalana
and Noy, Natasha
and Blomqvist, Eva",
title="FedX: Optimization Techniques for Federated Query Processing on Linked Data",
booktitle="The Semantic Web -- ISWC 2011",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="601--616",
abstract="Motivated by the ongoing success of Linked Data and the growing amount of semantic data sources available on the Web, new challenges to query processing are emerging. Especially in distributed settings that require joining data provided by multiple sources, sophisticated optimization techniques are necessary for efficient query processing. We propose novel join processing and grouping techniques to minimize the number of remote requests, and develop an effective solution for source selection in the absence of preprocessed metadata. We present FedX, a practical framework that enables efficient SPARQL query processing on heterogeneous, virtually integrated Linked Data sources. In experiments, we demonstrate the practicability and efficiency of our framework on a set of real-world queries and data sources from the Linked Open Data cloud. With FedX we achieve a significant improvement in query performance over state-of-the-art federated query engines.",
isbn="978-3-642-25073-6"
}

@inproceedings{Schwarte:2011:FOT:2063016.2063055,
address = {Berlin, Heidelberg},
author = {Schwarte, Andreas and Haase, Peter and Hose, Katja and Schenkel, Ralf and Schmidt, Michael},
booktitle = {Proceedings of the 10th International Conference on The Semantic Web - Volume Part I},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Tesis/Bibliograf{\'{i}}a/Data integration/978-3-642-25073-6{\_}38.pdf:pdf},
isbn = {978-3-642-25072-9},
pages = {601--616},
publisher = {Springer-Verlag},
series = {ISWC'11},
title = {{FedX: Optimization Techniques for Federated Query Processing on Linked Data}},
url = {http://dl.acm.org/citation.cfm?id=2063016.2063055},
year = {2011}
}

@inproceedings{Gorlitz:2011:SSE:2887352.2887354,
address = {Aachen, Germany, Germany},
author = {G{\"{o}}rlitz, Olaf and Staab, Steffen},
booktitle = {Proceedings of the Second International Conference on Consuming Linked Data - Volume 782},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Tesis/Bibliograf{\'{i}}a/Data integration/GoerlitzAndStaab{\_}COLD2011.pdf:pdf},
pages = {13--24},
publisher = {CEUR-WS.org},
series = {COLD'11},
title = {{SPLENDID: SPARQL Endpoint Federation Exploiting VOID Descriptions}},
url = {http://dl.acm.org/citation.cfm?id=2887352.2887354},
year = {2010}
}

@inproceedings{Corby:2012:KVI:2457524.2457672,
address = {Washington, DC, USA},
author = {Corby, Olivier and Gaignard, Alban and Zucker, Catherine Faron and Montagnat, Johan},
booktitle = {Proceedings of the The 2012 IEEE/WIC/ACM International Joint Conferences on Web Intelligence and Intelligent Agent Technology - Volume 01},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Tesis/Bibliograf{\'{i}}a/Data integration/KGRAM Versatile Inference and Query Engine for the Web of Linked Data.pdf:pdf},
isbn = {978-0-7695-4880-7},
keywords = {Data Mediation,Distributed Query Processing,Knowledge graphs,Modular architecture},
pages = {121--128},
publisher = {IEEE Computer Society},
series = {WI-IAT '12},
title = {{KGRAM Versatile Inference and Query Engine for the Web of Linked Data}},
url = {http://dl.acm.org/citation.cfm?id=2457524.2457672},
year = {2012}
}

@inproceedings{macina2016sparql,
address = {Poitiers, France},
author = {Macina, Abdoul and Montagnat, Johan and Corby, Olivier},
booktitle = {BDA 2016-32{\`{e}}me Conf{\'{e}}rence sur la Gestion de Donn{\'{e}}es-Principes, Technologies et Applications},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Tesis/Bibliograf{\'{i}}a/Data integration/macina{\_}montagnat{\_}corby{\_}bda2016.pdf:pdf},
title = {{A SPARQL distributed query processing engine addressing both vertical and horizontal data partitions}},
url = {https://hal.archives-ouvertes.fr/hal-01404165/file/macina{\_}montagnat{\_}corby{\_}bda2016.pdf},
year = {2016}
}

@article{VERBORGH2016184,
author = {Verborgh, Ruben and Sande, Miel Vander and Hartig, Olaf and Herwegen, Joachim Van and Vocht, Laurens De and Meester, Ben De and Haesendonck, Gerald and Colpaert, Pieter},
doi = {https://doi.org/10.1016/j.websem.2016.03.003},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Tesis/Bibliograf{\'{i}}a/Data integration/Triple Pattern Fragments a Low-cost Knowledge Graph Interface for the Web.pdf:pdf},
issn = {1570-8268},
journal = {Web Semantics: Science, Services and Agents on the World Wide Web},
keywords = {Linked Data,Linked Data Fragments,Querying,SPARQL},
pages = {184--206},
title = {{Triple Pattern Fragments: A low-cost knowledge graph interface for the Web}},
url = {http://www.sciencedirect.com/science/article/pii/S1570826816000214},
volume = {37-38},
year = {2016}
}

@article{KHARLAMOV20173,
annote = {Industry and In-use Applications of Semantic Technologies},
author = {Kharlamov, Evgeny and Hovland, Dag and Skj{\ae}veland, Martin G and Bilidas, Dimitris and Jim{\'{e}}nez-Ruiz, Ernesto and Xiao, Guohui and Soylu, Ahmet and Lanti, Davide and Rezk, Martin and Zheleznyakov, Dmitriy and Giese, Martin and Lie, Hallstein and Ioannidis, Yannis and Kotidis, Yannis and Koubarakis, Manolis and Waaler, Arild},
doi = {https://doi.org/10.1016/j.websem.2017.05.005},
file = {:D$\backslash$:/Superacion/ARTICLES/POR LEER/Ontology-based data access/497-875-1-SM.pdf:pdf},
issn = {1570-8268},
journal = {Web Semantics: Science, Services and Agents on the World Wide Web},
keywords = {Bootstrapping,Evaluation,Ontology Based Data Access,Optimisations,Optique platform,Statoil,System deployment},
pages = {3--36},
title = {{Ontology Based Data Access in Statoil}},
url = {http://www.sciencedirect.com/science/article/pii/S1570826817300276},
volume = {44},
year = {2017}
}

@inproceedings{Calvanese:2015:SOY:2991147.2991152,
address = {New York, NY, USA},
author = {Calvanese, Diego and Cogrel, Benjamin and Komla-Ebri, Sarah and Lanti, Davide and Rezk, Martin and Xiao, Guohui},
booktitle = {Revised Selected Papers of the ESWC 2015 Satellite Events on The Semantic Web: ESWC 2015 Satellite Events - Volume 9341},
doi = {10.1007/978-3-319-25639-9_4},
file = {:D$\backslash$:/Superacion/ARTICLES/POR LEER/Ontology-based data access/How to Stay Ontop of Your Data - Databases,Ontologies and More.pdf:pdf},
isbn = {978-3-319-25638-2},
keywords = {OBDA,OWL,OWL{\'{z}}2{\'{z}}QL,Ontop framework,R2RML,SPARQL},
pages = {20--25},
publisher = {Springer-Verlag New York, Inc.},
title = {{How to Stay Ontop of Your Data: Databases, Ontologies and More}},
url = {http://dx.doi.org/10.1007/978-3-319-25639-9{\_}4},
year = {2015}
}

@inproceedings{Tabares-Martin2016,
address = {Havana},
author = {Tabares-Mart{\'{i}}n, Leandro and Fern{\'{a}}ndez-Pe{\~{n}}a, F{\'{e}}lix Oscar and Leiva-Mederos, Amed},
booktitle = {2nd International Workshop of Semantic Web},
editor = {Hidalgo-Delgado, Yusniel and Leiva-Mederos, Amed Abel},
file = {:D$\backslash$:/Superacion/INVESTIGACI{\'{O}}N/Mis Art{\'{i}}culos/Info2016/Paper/IWSW.pdf:pdf},
keywords = {authority control,cess,linked open data,obda,ontology-based data ac-,semantic web},
pages = {11--22},
publisher = {cewr-ws},
title = {{AUCTORITAS : A Semantic Web-based tool for Authority Control}},
url = {http://ceur-ws.org/Vol-1797/paper2.pdf},
year = {2016}
}

@incollection{Poggi:2008:LDO:1793934.1793939,
address = {Berlin, Heidelberg},
author = {Poggi, Antonella and Lembo, Domenico and Calvanese, Diego and {De Giacomo}, Giuseppe and Lenzerini, Maurizio and Rosati, Riccardo},
booktitle = {Journal on Data Semantics X},
chapter = {Linking da},
editor = {Spaccapietra, Stefano},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Tesis/Bibliograf{\'{i}}a/Data integration/Journal{\_}on{\_}Data{\_}Semantics{\_}VIII.pdf:pdf},
isbn = {3-540-77687-7, 978-3-540-77687-1},
pages = {133--173},
publisher = {Springer-Verlag},
title = {{Linking data to ontologies}},
url = {http://dl.acm.org/citation.cfm?id=1793934.1793939 https://www.researchgate.net/profile/Ilya{\_}Zaihrayeu/publication/239578895{\_}Journal{\_}on{\_}Data{\_}Semantics{\_}VIII/links/551a7f070cf26cbb81a2e1d2.pdf{\#}page=143},
year = {2008}
}

@article{Daraio2016,
abstract = {This paper proposes an Ontology-Based Data Management (OBDM) approach to coordinate, integrate and maintain the data needed for Science, Technology and Innovation (STI) policy development. The OBDM approach is a form of integration of information in which the global schema of data is substituted by the conceptual model of the domain, formally specified through an ontology. Implemented in Sapientia, the ontology of multi-dimensional research assessment, it offers a transparent platform as the base for the assessment process; it enables one to define and specify in an unambiguous way the indicators on which the evaluation is based, and to track their evolution over time; also it allows to the analysis of the effects of the actual use of the indicators on the behavior of scholars, and spot opportunistic behaviors; and it provides a monitoring system to track over time the changes in the established evaluation criteria and their consequences for the research system. It is argued that easier access to and a more transparent view of scientific-scholarly outcomes help to improve the understanding of basic science and the communication of research outcomes to the wider public. An OBDM approach could successfully contribute to solve some of the key issues in the integration of heterogeneous data for STI policies.},
author = {Daraio, Cinzia and Lenzerini, Maurizio and Leporelli, Claudio and Moed, Henk F and Naggar, Paolo and Bonaccorsi, Andrea and Bartolucci, Alessandro},
doi = {10.1007/s11192-015-1814-0},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Tesis/Bibliograf{\'{i}}a/Data integration/Data integration for research and innovation policy an Ontology-Based Data Management approach.pdf:pdf},
issn = {1588-2861},
journal = {Scientometrics},
month = {feb},
number = {2},
pages = {857--871},
title = {{Data integration for research and innovation policy: an Ontology-Based Data Management approach}},
url = {https://doi.org/10.1007/s11192-015-1814-0},
volume = {106},
year = {2016}
}
@inproceedings{Kharlamov:2016:OIS:2882903.2899385,
address = {New York, NY, USA},
author = {Kharlamov, Evgeny and Brandt, Sebastian and Jimenez-Ruiz, Ernesto and Kotidis, Yannis and Lamparter, Steffen and Mailis, Theofilos and Neuenstadt, Christian and {\"{O}}z{\c{c}}ep, {\"{O}}zg{\"{u}}r and Pinkel, Christoph and Svingos, Christoforos and Zheleznyakov, Dmitriy and Horrocks, Ian and Ioannidis, Yannis and Moeller, Ralf},
booktitle = {Proceedings of the 2016 International Conference on Management of Data},
doi = {10.1145/2882903.2899385},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Tesis/Bibliograf{\'{i}}a/Data integration/sigmod-16-siemens-demo.pdf:pdf},
isbn = {978-1-4503-3531-7},
keywords = {information integration,ontologies,semantic web,siemens},
pages = {2109--2112},
publisher = {ACM},
series = {SIGMOD '16},
title = {{Ontology-Based Integration of Streaming and Static Relational Data with Optique}},
url = {http://doi.acm.org/10.1145/2882903.2899385},
year = {2016}
}

@article{Hevner:2004:DSI:2017212.2017217,
address = {Minneapolis, MN, USA},
author = {Hevner, Alan R and March, Salvatore T and Park, Jinsoo and Ram, Sudha},
file = {:D$\backslash$:/Superacion/Doctorado/Conferencia IT Artifacts/it artifacts/Ciencias del dise{\~{n}}o/HEVNER{\_}2004.pdf:pdf},
issn = {0276-7783},
journal = {MIS Q.},
keywords = {business environment,creativity,design artifact,design science,experimental methods,information systems research methodologies,search strategies,technology infrastructure},
number = {1},
pages = {75--105},
publisher = {Society for Information Management and The Management Information Systems Research Center},
title = {{Design Science in Information Systems Research}},
url = {http://dl.acm.org/citation.cfm?id=2017212.2017217},
volume = {28},
year = {2004}
}

@article{Denning:1997:NSC:253671.253755,
address = {New York, NY, USA},
author = {Denning, Peter J},
doi = {10.1145/253671.253755},
file = {:D$\backslash$:/Superacion/Doctorado/Conferencia IT Artifacts/it artifacts/Ciencias del dise{\~{n}}o/A new social contract for research.pdf:pdf},
issn = {0001-0782},
journal = {Communications of the ACM},
number = {2},
pages = {132--134},
publisher = {ACM},
title = {{A New Social Contract for Research}},
url = {http://doi.acm.org/10.1145/253671.253755},
volume = {40},
year = {1997}
}

@article{March:1995:DNS:1700865.1700867,
address = {Amsterdam, The Netherlands, The Netherlands},
author = {March, Salvatore T and Smith, Gerald F},
doi = {10.1016/0167-9236(94)00041-2},
file = {:D$\backslash$:/Superacion/Doctorado/Conferencia IT Artifacts/it artifacts/Ciencias del dise{\~{n}}o/Design and Natural Science Research on Information Technology.pdf:pdf},
issn = {0167-9236},
journal = {Decision Support Systems},
keywords = {Design science,Information system research,Information technology,Natural science},
number = {4},
pages = {251--266},
publisher = {Elsevier Science Publishers B. V.},
title = {{Design and Natural Science Research on Information Technology}},
url = {http://dx.doi.org/10.1016/0167-9236(94)00041-2},
volume = {15},
year = {1995}
}

@book{Simon:1996:SA:237774,
address = {Cambridge, MA, USA},
author = {Simon, Herbert A},
edition = {3rd},
file = {:D$\backslash$:/Superacion/Doctorado/Conferencia IT Artifacts/it artifacts/Ciencias del dise{\~{n}}o/The sciences of the artificial.pdf:pdf},
isbn = {0-262-69191-4},
publisher = {MIT Press},
title = {{The Sciences of the Artificial}},
year = {1996}
}

@inproceedings{Peffers2006,
abstract = {The authors design and demonstrate a process for carrying out design science (DS) research in information systems and demonstrate use of the process to conduct re- search in two case studies. Several IS researchers have pioneered the acceptance of DS research in IS, but in the last 15 years little DS research has been done within the discipline. The lack of a generally accepted process for DS research in IS may have contributed to this problem. We sought to design a design science research process (DSRP) model that would meet three objectives: it would be consistent with prior lit- erature, it would provide a nominal process model for doing DS research, and it would provide a mental model for presenting and appreciating DS research in IS. The process includes six steps: problem identification and motivation, objectives for a solution, design and development, evaluation, and communication. We demonstrated the process by using it in this study and by presenting two case studies, one in IS planning to develop application ideas for mobile financial services and another in re- quirements engineering to specify feature requirements for a self service advertising design and sales system intended for wide audience end users. The process effectively satisfies the three objectives and has the potential to help aid the acceptance of DS research in the IS discipline. Keywords:},
archivePrefix = {arXiv},
arxivId = {z0022},
author = {Peffers, Ken and Tuunanen, Tuure and Gengler, Charles E and Rossi, Matti and Hui, Wendy and Virtanen, Ville and Bragge, Johanna},
booktitle = {Proceedings of Design Research in Information Systems and Technology DESRIST'06},
doi = {10.2753/MIS0742-1222240302},
eprint = {z0022},
file = {:D$\backslash$:/Superacion/Doctorado/Conferencia IT Artifacts/it artifacts/Ciencias del dise{\~{n}}o/THE DESIGN SCIENCE RESEARCH PROCESS - A MODEL FOR PRODUCING AND PRESENTING INFORMATION SYSTEMS RESEARCH.pdf:pdf},
isbn = {1702807118},
issn = {0742-1222},
keywords = {Design science,and information systems development.,case study,design science research process,process model,requirements elicitation,requirements engineering},
pages = {83--106},
pmid = {28843849},
title = {{The Design Science Research Process: A Model for Producing and Presenting Information Systems Research}},
volume = {24},
year = {2006}
}
@phdthesis{GarciaNoguera2009,
abstract = {El desarrollo de sistemas de cierta envergadura requiere la participaci{\'{o}}n activa y conjunta de equipos humanos llamados a entenderse por el bien y el {\'{e}}xito del producto final. El punto de partida es una adecuada comprensi{\'{o}}n y descripci{\'{o}}n del dominio en la fase de an{\'{a}}lisis del sistema. En este proceso, son muchas las cuestiones a considerar: recursos, requisitos (funcionales y no funcionales), grupos, usuarios, etc. La sofisticaci{\'{o}}n de la propia realidad o la distancia que pueda haber con los desarrolladores del sistema, entre otros factores, hacen necesaria la construcci{\'{o}}n de modelos que, mediante procesos de abstracci{\'{o}}n apropiados, sirvan para comunicar el mundo f{\'{i}}sico y social en el que se desenvuelve una organizaci{\'{o}}n [Schreiber 1994]. La Figura I.1 muestra un modelo para un sistema de control de equipajes en un aeropuerto. En este modelo se han representado distintos tipos de cintas de transporte para maletas, el flujo de desplazamiento que siguen {\'{e}}stas, dispositivos de escaneo y tambi{\'{e}}n el lugar desde ser{\'{i}}an controladas por los operadores del sistema.},
author = {{Garc{\'{i}}a Noguera}, Manuel},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Tesis/Bibliograf{\'{i}}a/18014094.pdf:pdf},
isbn = {9788469230886},
pages = {205},
school = {Universidad de Granada},
title = {{Modelado Y An{\'{a}}lisis De Sistemas Cscw Siguiendo Un Enfoque De Ingenier{\'{i}}a Dirigida Por Ontolog{\'{i}}as}},
type = {Tesis doctoral},
url = {http://0-hera.ugr.es.adrastea.ugr.es/tesisugr/18014094.pdf},
year = {2009}
}

@article{Eisenberg:1999:SFK:309844.310075,
address = {New York, NY, USA},
author = {Eisenberg, Andrew and Melton, Jim},
doi = {10.1145/309844.310075},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Tesis/Bibliograf{\'{i}}a/SQL 1999 formerly known as SQL3.pdf:pdf},
issn = {0163-5808},
journal = {SIGMOD Rec.},
number = {1},
pages = {131--138},
publisher = {ACM},
title = {{SQL: 1999, Formerly Known As SQL3}},
url = {http://doi.acm.org/10.1145/309844.310075},
volume = {28},
year = {1999}
}

@InProceedings{10.1007/978-981-10-8276-4_22,
author="Alfred, Rayner
and Chung, Chong Jia
and On, Chin Kim
and Ibrahim, Ag Asri Ag
and Sainin, Mohd Shamrie
and Pandiyan, Paulraj Murugesa",
editor="Alfred, Rayner
and Iida, Hiroyuki
and Ag. Ibrahim, Ag. Asri
and Lim, Yuto",
title="Data Fusion Based on Self-Organizing Map Approach to Learning Medical Relational Data",
booktitle="Computational Science and Technology",
year="2018",
publisher="Springer Singapore",
address="Singapore",
pages="230--240",
abstract="Amount of data generated and stored in relational databases has motivated numerous researchers to study and develop learning algorithms on learning relational data mining. One of the most important relational tasks is to discover knowledge from relational data for a better decision making. Despite that, various representations can be generated using the same data by applying the Self-Organizing Map (SOM) methods in clustering relational data. This can be achieved by tuning the parameters used in Self-Organizing Map (SOM), such as the number of clustering, weights, seeds, epoch and others. Thus, this paper proposes a summarization method that applies SOM as the main algorithm to cluster relational data and applies the concept of data fusion in order to get better results in learning relational data. Input data obtained from Dynamic Aggregation of Relational Attributes will be clustered using the SOM method by tuning the SOM parameters. Results generated will be fused and embedded into the target table to form a single representation. A few representations will be formed and fed into the classifiers (J48 Decision Tree and Na{\"i}ve Bayes classification model) as input data. Throughout the experiments conducted, representations that are extracted by tuning the number of cluster produced better results compared to the representations that are extracted by tuning the other parameters. Overall, the data summarization approach based on individual data fusion is found to perform better compared to the other types of data fusion. In addition to that, the clusters based data fusion with average number of clusters provided better accuracy performances compared to clusters based data fusion with small and large number of clusters.",
isbn="978-981-10-8276-4"
}
@incollection{BUCKLES1993660,
title = "A \{FUZZY\} \{REPRESENTATION\} \{OF\} \{DATA\} \{FOR\} \{RELATIONAL\} \{DATABASES\} ",
editor = "Dubois, Didier and Prade, Henri  and Yager, Ronald R. ",
booktitle = "Readings in Fuzzy Sets for Intelligent Systems ",
publisher = "Morgan Kaufmann",
edition = "",
address = "",
year = "1993",
pages = "660 - 666",
isbn = "978-1-4832-1450-4",
doi = "https://doi.org/10.1016/B978-1-4832-1450-4.50071-7",
url = "https://www.sciencedirect.com/science/article/pii/B9781483214504500717",
author = "Billy P. BUCKLES and Frederick E. PETRY"
}
@incollection{Hristidis2002670,
title = "Chapter 58 - Discover: Keyword Search in Relational Databases ",
editor = "Bernstein, Philip A. and , and Ioannidis, Yannis E. and , and Ramakrishnan, Raghu and ,  and Papadias, Dimitris ",
booktitle = "\{VLDB\} '02: Proceedings of the 28th International Conference on Very Large Databases ",
publisher = "Morgan Kaufmann",
edition = "",
address = "San Francisco",
year = "2002",
pages = "670 - 681",
isbn = "978-1-55860-869-6",
doi = "https://doi.org/10.1016/B978-155860869-6/50065-2",
url = "https://www.sciencedirect.com/science/article/pii/B9781558608696500652",
author = "Vagelis Hristidis and Yannis Papakonstantinou"
}
@article{Leavitt2010,
author = {Leavitt, Neal},
doi = {https://doi.org/10.1109/MC.2010.58},
issn = {0018-9162},
journal = {Computer},
number = {2},
title = {{Will NoSQL Databases Live Up to Their Promise?}},
url = {http://ieeexplore.ieee.org/abstract/document/5410700/},
volume = {43},
year = {2010}
}
@inproceedings{Zaki2017,
address = {Langkawi, Malaysia},
author = {Zaki, Nazar and Tennakoon, Chandana and Al-Ashwal, Hany},
booktitle = {International Conference on Research and Innovation in Information Systems (ICRIIS)},
doi = {https://doi.org/10.1109/ICRIIS.2017.8002465},
publisher = {IEEE Computer Society},
title = {{Knowledge graph construction and search for biological databases}},
url = {http://ieeexplore.ieee.org/abstract/document/8002465/},
year = {2017}
}
@article{BRISABOA2017106,
title = "Compressed representation of dynamic binary relations with applications",
journal = "Information Systems",
volume = "69",
pages = "106 - 123",
year = "2017",
issn = "0306-4379",
doi = "https://doi.org/10.1016/j.is.2017.05.003",
url = "http://www.sciencedirect.com/science/article/pii/S030643791630535X",
author = "Nieves R. Brisaboa and Ana Cerdeira-Pena and Guillermo de Bernardo and Gonzalo Navarro",
keywords = "Compression, Dynamic binary relations, k-tree"
}
@misc{W3CSPARQLWorkingGroup2013,
author = {{W3C SPARQL Working Group}},
title = {{SPARQL 1.1 Overview}},
url = {https://www.w3.org/TR/sparql11-overview/},
urldate = {5/3/2018},
year = {2013}
}
@inbook{Pautasso2014,
abstract = {RESTful Web services are software services which are published on the Web, taking full advantage and making correct use of the HTTP protocol. This chapter gives an introduction to the REST architectural style and how it can be used to design Web service APIs. We summarize the main design constraints of the REST architectural style and discuss how they impact the design of so-called RESTful Web service APIs. We give examples on how the Web can be seen as a novel kind of software connector, which enables the coordination of distributed, stateful and autonomous software services. We conclude the chapter with a critical overview of a set of emerging technologies which can be used to support the development and operation of RESTful Web services.},
address = {New York, NY},
author = {Pautasso, Cesare},
booktitle = {Web Services Foundations},
doi = {10.1007/978-1-4614-7518-7_2},
editor = {Bouguettaya, Athman and Sheng, Quan Z and Daniel, Florian},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Tesis/Bibliograf{\'{i}}a/Pautasso2014.pdf:pdf},
isbn = {978-1-4614-7518-7},
pages = {31--51},
publisher = {Springer New York},
title = {{RESTful Web Services: Principles, Patterns, Emerging Technologies}},
url = {https://doi.org/10.1007/978-1-4614-7518-7{\_}2},
year = {2014}
}
@article{Fernandez-Pena2015,
abstract = {This paper introduces a conceptual data model for representing data views using ontologies. The main objective is to avoid the recodification of information systems when business logic changes appear. The experiments carried out are supported by a prototype of data retrieval tool capable of the dynamic generation of user interfaces based on the proposed ontology. As result of the experimentation, the practicability of the proposal has been proved. Results shown in here are a first step in a semantic-approach for the integration of open data sources.},
author = {Fern{\'{a}}ndez-Pe{\~{n}}a, F{\'{e}}lix and Acosta-S{\'{a}}nchez, Rolando and Ponce-Toste, Yudit},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Tesis/Bibliograf{\'{i}}a/Art{\'{i}}culo ViewOnto.pdf:pdf},
journal = {Ciencias de la Informaci{\'{o}}n},
keywords = {Sistemas de informaci{\'{o}}n,bases de datos,data,information systems,ontology,ontolog{\'{i}}a,palabras clave,relational databases,sistemas de informaci{\'{o}}n,view,vista de dato},
number = {1},
pages = {19--25},
title = {{ViewOnto: modelo conceptual para la generaci{\'{o}}n autom{\'{a}}tica de vistas de datos}},
url = {http://www.redalyc.org/articulo.oa?id=181439409003},
volume = {46},
year = {2015}
}
@book{Gomez-Perez:2007:OEE:1199560,
address = {Secaucus, NJ, USA},
author = {G{\'{o}}mez-P{\'{e}}rez, Asunci{\'{o}}n and Fern{\'{a}}ndez-L{\'{o}}pez, Mariano and Corcho, Oscar},
isbn = {1846283965},
publisher = {Springer-Verlag New York, Inc.},
title = {{Ontological Engineering: With Examples from the Areas of Knowledge Management, e-Commerce and the Semantic Web. (Advanced Information and Knowledge Processing)}},
year = {2007}
}

@article{JANNACH2009136,
annote = {The Web of Data},
author = {Jannach, Dietmar and Shchekotykhin, Kostyantyn and Friedrich, Gerhard},
doi = {https://doi.org/10.1016/j.websem.2009.04.002},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Tesis/Bibliograf{\'{i}}a/Ontology instantiation/jannach2009.pdf:pdf},
issn = {1570-8268},
journal = {Web Semantics: Science, Services and Agents on the World Wide Web},
keywords = {Knowledge extraction,Ontology instantiation,Web crawling,Web mining},
number = {3},
pages = {136--153},
title = {{Automated ontology instantiation from tabular web sources—The AllRight system}},
url = {http://www.sciencedirect.com/science/article/pii/S1570826809000055},
volume = {7},
year = {2009}
}
@ARTICLE{1179189, 
author={H. Alani and Sanghee Kim and D. E. Millard and M. J. Weal and W. Hall and P. H. Lewis and N. R. Shadbolt}, 
journal={IEEE Intelligent Systems}, 
title={Automatic ontology-based knowledge extraction from Web documents}, 
year={2003}, 
volume={18}, 
number={1}, 
pages={14-21}, 
keywords={Internet;classification;information resources;information retrieval;knowledge acquisition;knowledge based systems;natural languages;nomenclature;Artequakt project;Semantic Web;Web documents;Web page annotations;automatic ontology-based knowledge extraction;domain knowledge classification;knowledge access;knowledge base;lexicon-based term expansion;machine-readable format;natural language processing;online documents;terminology;unstructured text;Assembly;Biographies;Data mining;Image databases;Image reconstruction;Ontologies;Painting;Semantic Web;Terminology;Web pages}, 
doi={10.1109/MIS.2003.1179189}, 
ISSN={1541-1672}, 
month={Jan},}

@inproceedings{10.1007/978-0-387-87685-6_30,
abstract = {One of the challenging tasks in the context of Ontological Engineering is to automatically or semi-automatically support the process of Ontology Learning and Ontology Population from semi-structured documents (texts). In this paper we describe a Semi-Automatic Ontology Instantiation method from natural language text, in the domain of Risk Management. This method is composed from three steps 1 ) Annotation with part-of-speech tags, 2) Semantic Relation Instances Extraction, 3) Ontology instantiation process. It's based on combined NLP techniques using human intervention between steps 2 and 3 for control and validation. Since it heavily relies on linguistic knowledge it is not domain dependent which is a good feature for portability between the different fields of risk management application. The proposed methodology uses the ontology of the PRIMA1 project (supported by the European community) as a Generic Domain Ontology and populates it via an available corpus. A first validation of the approach is done through an experiment with Chemical Fact Sheets from Environmental Protection Agency2.},
address = {Boston, MA},
author = {Makki, Jawad and Alquier, Anne-Marie and Prince, Violaine},
booktitle = {Intelligent Information Processing IV},
editor = {Shi, Zhongzhi and Mercier-Laurent, E and Leake, D},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Tesis/Bibliograf{\'{i}}a/Ontology instantiation/978-0-387-87685-6{\_}30.pdf:pdf},
isbn = {978-0-387-87685-6},
pages = {254--265},
publisher = {Springer US},
title = {{Semi Automatic Ontology Instantiation in the domain of Risk Management}},
year = {2008}
}

@inproceedings{viljanen2008publishing,
author = {Viljanen, Kim and Tuominen, Jouni and Hyv{\"{o}}nen, Eero},
booktitle = {Proceedings of the 4th Workshop on Scripting for the Semantic Web (SFSW2008)},
file = {:D$\backslash$:/Superacion/ARTICLES/READED/2008/Publishing and Using Ontologies as Mashup Services.pdf:pdf},
publisher = {5th European Semantic Web Conference},
title = {{Publishing and using ontologies as mashup services}},
year = {2008}
}

@book{Wohlin2012,
abstract = {Empirical software engineering research can be organized in several ways, including experiments, cases studies, and surveys. Experiments sample over the variables, trying to represent all possible cases; cases studies sample from the variables, representing only the typical cases(s). Every case study or experiment should have a hypothesis to express the desired result. The experimental design is especially important because it identifies key variables and their relationships. The design uses balancing, blocking, and local control to help minimize error. Analysis techniques depend on the design, the distribution of the data, and the type of investigation being carried out. Different techniques allow us to look at variable interaction and to look at combinations of effects. Using a technique similar to a board game, we can determine when we have enough evidence to demonstrate clear relationships among variables. {\textcopyright} 1997 Academic Press Inc.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Wohlin, Claes and Runeson, Per and H{\"{o}}st, Martin and Ohlsson, Magnus C. and Regnell, Bj{\"{o}}rn and Wessl{\'{e}}n, Anders},
booktitle = {Experimentation in Software Engineering},
doi = {10.1007/978-3-642-29044-2},
eprint = {arXiv:1011.1669v3},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Tesis/Bibliograf{\'{i}}a/Validaci{\'{o}}n/Experimentation in Software Engineering.pdf:pdf},
isbn = {3642290434, 9783642290435},
pages = {1--236},
pmid = {25246403},
publisher = {3642290434, 9783642290435},
title = {{Experimentation in software engineering}},
volume = {9783642290},
year = {2012}
}

@book{Runeson:2012:CSR:2361717,
abstract = {Based on their own experiences of in-depth case studies of software projects in international corporations, in this book the authors present detailed practical guidelines on the preparation, conduct, design and reporting of case studies of software engineering. This is the first software engineering specific book on the case study research method.},
author = {Runeson, Per and Host, Martin and Rainer, Austen and Regnell, Bj{\"{o}}rn},
booktitle = {John Wiley {\&} Sons, Inc},
doi = {10.1002/9781118181034},
edition = {1st},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Tesis/Bibliograf{\'{i}}a/Validaci{\'{o}}n/case-study-research-in-software-engineering.pdf:pdf},
isbn = {9781118104354},
pages = {216},
publisher = {Wiley Publishing},
title = {{Case Study Research in Software Engineering}},
url = {http://www.wiley.com/WileyCDA/WileyTitle/productCd-1118104358.html{\%}5Cnhttp://doi.wiley.com/10.1002/9781118181034},
year = {2012}
}

@book{stake1995art,
  title={The art of case study research},
  author={Stake, Robert E},
  year={1995},
  publisher={SAGE Publications}
}

@inproceedings{Petersen:2009:CIS:1671248.1671293,
address = {Washington, DC, USA},
author = {Petersen, Kai and Wohlin, Claes},
booktitle = {Proceedings of the 2009 3rd International Symposium on Empirical Software Engineering and Measurement},
doi = {10.1109/ESEM.2009.5316010},
file = {:D$\backslash$:/Superacion/MAESTR{\'{I}}A/Tesis/Bibliograf{\'{i}}a/Validaci{\'{o}}n/petersen2009.pdf:pdf},
isbn = {978-1-4244-4842-5},
pages = {401--404},
publisher = {IEEE Computer Society},
series = {ESEM '09},
title = {{Context in Industrial Software Engineering Research}},
url = {http://dx.doi.org/10.1109/ESEM.2009.5316010},
year = {2009}
}

@article{kitchenham1995case,
  title={Case studies for method and tool evaluation},
  author={Kitchenham, Barbara and Pickard, Lesley and Pfleeger, Shari Lawrence},
  journal={IEEE software},
  volume={12},
  number={4},
  pages={52--62},
  year={1995},
  publisher={IEEE}
}

@inproceedings{duboc2006framework,
author = {Duboc, Leticia and Rosenblum, David S and Wicks, Tony},
booktitle = {Proceedings of the 28th international conference on Software engineering},
file = {:D$\backslash$:/Superacion/ARTICLES/POR LEER/Escalabilidad de software/4990.pdf:pdf},
organization = {ACM},
pages = {949--952},
title = {{A framework for modelling and analysis of software systems scalability}},
year = {2006}
}

@Article{Lethbridge2005,
author="Lethbridge, Timothy C.
and Sim, Susan Elliott
and Singer, Janice",
title="Studying Software Engineers: Data Collection Techniques for Software Field Studies",
journal="Empirical Software Engineering",
year="2005",
month="Jul",
day="01",
volume="10",
number="3",
pages="311--341",
abstract="Software engineering is an intensively people-oriented activity, yet too little is known about how designers, maintainers, requirements analysts and all other types of software engineers perform their work. In order to improve software engineering tools and practice, it is therefore essential to conduct field studies, i.e. to study real practitioners as they solve real problems. To do so effectively, however, requires an understanding of the techniques most suited to each type of field study task. In this paper, we provide a taxonomy of techniques, focusing on those for data collection. The taxonomy is organized according to the degree of human intervention each requires. For each technique, we provide examples from the literature, an analysis of some of its advantages and disadvantages, and a discussion of how to use it effectively. We also briefly talk about field study design in general, and data analysis.",
issn="1573-7616",
doi="10.1007/s10664-005-1290-x",
url="https://doi.org/10.1007/s10664-005-1290-x"
}

@phdthesis{Calzadilla-Reyes2015,
author = {Calzadilla-Reyes, Daili{\'{e}}n and Ruano-Alvarez, Wilbert A.},
pages = {1 -- 104},
school = {Universidad de las Ciencias Inform{\'{a}}ticas},
title = {{AUCTORITAS Sistema de apoyo para el control de autoridades}},
type = {Trabajo de diploma},
year = {2015}
}

@phdthesis{Gonzalez-Barroso2016,
author = {Gonz{\'{a}}lez-Barroso, Flavia and P{\'{e}}rez-Gonz{\'{a}}lez, Darayne},
pages = {1 -- 114},
school = {Universidad de las Ciencias Inform{\'{a}}ticas},
title = {{AUCTORITAS 2.0: Sistema de apoyo para el Control de Autoridades}},
type = {Trabajo de diploma},
year = {2016}
}

@ARTICLE{799955,
author={C. B. Seaman},
journal={IEEE Transactions on Software Engineering},
title={Qualitative methods in empirical studies of software engineering},
year={1999},
volume={25},
number={4},
pages={557-572},
keywords={human factors;project management;software development management;user interfaces;data collection;empirical studies;human aspects;human behaviour;nontechnical aspects;qualitative methods;qualitative research methods;quantitative methods;real software engineering studies;research community;research methods;research questions;software development;software engineering;Computer industry;Data analysis;Design for experiments;Design methodology;Helium;Humans;Laboratories;Programming;Software development management;Software engineering},
doi={10.1109/32.799955},
ISSN={0098-5589},
month={Jul},}
